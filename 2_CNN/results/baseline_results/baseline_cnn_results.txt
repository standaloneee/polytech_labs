======================================================================
BASELINE CNN - РЕЗУЛЬТАТЫ ОБУЧЕНИЯ
======================================================================

АРХИТЕКТУРА:
  Conv2d(1, 32, 3) + ReLU + MaxPool(2)
  Conv2d(32, 64, 3) + ReLU + MaxPool(2)
  Flatten + FC(3136, 128) + ReLU + Dropout(0.5)
  FC(128, 11)

ГИПЕРПАРАМЕТРЫ:
  Epochs: 20
  Batch size: 128
  Learning rate: 0.001
  Optimizer: Adam
  Dropout: 0.5

ПАРАМЕТРЫ МОДЕЛИ: 421,771

РЕЗУЛЬТАТЫ:
  Test Loss: 0.4777
  Test Accuracy: 89.96%

СРАВНЕНИЕ С MLP:
  MLP (ансамбль): 80.83%
  CNN (baseline): 89.96%
  Улучшение: +9.13%

ИСТОРИЯ ОБУЧЕНИЯ:
Epoch | Train Loss | Train Acc | Val Loss | Val Acc
------------------------------------------------------------
    1 |     1.0293 |     65.44 |   0.2464 |   94.82
    2 |     0.5010 |     83.78 |   0.2181 |   94.31
    3 |     0.3606 |     87.83 |   0.1713 |   96.20
    4 |     0.2938 |     89.92 |   0.1535 |   95.90
    5 |     0.2505 |     91.37 |   0.1466 |   96.32
    6 |     0.2086 |     92.84 |   0.1642 |   96.70
    7 |     0.1818 |     93.51 |   0.1959 |   96.24
    8 |     0.1625 |     94.24 |   0.1624 |   96.70
    9 |     0.1444 |     94.84 |   0.1835 |   95.74
   10 |     0.1393 |     95.01 |   0.1847 |   96.11
   11 |     0.1222 |     95.71 |   0.1850 |   96.36
   12 |     0.1133 |     95.81 |   0.1909 |   96.70
   13 |     0.0995 |     96.35 |   0.1991 |   96.70
   14 |     0.0943 |     96.74 |   0.1918 |   96.40
   15 |     0.0910 |     96.66 |   0.2156 |   96.28
   16 |     0.0883 |     96.90 |   0.2005 |   96.78
   17 |     0.0785 |     97.09 |   0.2064 |   96.57
   18 |     0.0735 |     97.35 |   0.2365 |   96.40
   19 |     0.0678 |     97.64 |   0.2169 |   96.49
   20 |     0.0604 |     97.93 |   0.1992 |   96.74
