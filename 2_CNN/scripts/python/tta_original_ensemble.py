"""
Test-Time Augmentation (TTA) Ð´Ð»Ñ Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð°Ð½ÑÐ°Ð¼Ð±Ð»Ñ 5 Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹

ÐŸÑ€Ð¸Ð¼ÐµÐ½ÑÐµÑ‚ TTA Ðº Ð»ÑƒÑ‡ÑˆÐµÐ¼Ñƒ Ð°Ð½ÑÐ°Ð¼Ð±Ð»ÑŽ (91.16%)
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms
import numpy as np
import json
import medmnist
from medmnist import INFO
from tqdm import tqdm


# ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ ÑƒÑÑ‚Ñ€Ð¾Ð¹ÑÑ‚Ð²Ð°
if torch.cuda.is_available():
    device = torch.device('cuda')
elif torch.backends.mps.is_available():
    device = torch.device('mps')
else:
    device = torch.device('cpu')

print(f'Device: {device}\n')


# ===========================================================================
# ÐÑ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ñ‹ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹
# ===========================================================================

class ResidualBlock(nn.Module):
    def __init__(self, channels):
        super(ResidualBlock, self).__init__()
        self.conv1 = nn.Conv2d(channels, channels, 3, padding=1)
        self.bn1 = nn.BatchNorm2d(channels)
        self.conv2 = nn.Conv2d(channels, channels, 3, padding=1)
        self.bn2 = nn.BatchNorm2d(channels)

    def forward(self, x):
        residual = x
        out = F.relu(self.bn1(self.conv1(x)))
        out = self.bn2(self.conv2(out))
        out += residual
        out = F.relu(out)
        return out


class ResNetLikeCNN(nn.Module):
    def __init__(self, num_classes=11, dropout=0.3, hidden_dim=64):
        super(ResNetLikeCNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 64, 3, padding=1)  # Fixed to 64
        self.bn1 = nn.BatchNorm2d(64)
        self.pool = nn.MaxPool2d(2, 2)
        self.res_block1 = ResidualBlock(64)
        self.res_block2 = ResidualBlock(64)
        self.conv2 = nn.Conv2d(64, 128, 3, padding=1, stride=2)
        self.bn2 = nn.BatchNorm2d(128)
        self.global_pool = nn.AdaptiveAvgPool2d(1)
        self.fc = nn.Linear(128, num_classes)
        self.dropout = nn.Dropout(dropout)

    def forward(self, x):
        x = F.relu(self.bn1(self.conv1(x)))
        x = self.pool(x)
        x = self.res_block1(x)
        x = self.res_block2(x)
        x = F.relu(self.bn2(self.conv2(x)))
        x = self.global_pool(x)
        x = x.view(x.size(0), -1)
        x = self.dropout(x)
        x = self.fc(x)
        return x


class BatchNormCNN(nn.Module):
    def __init__(self, num_classes=11, dropout=0.3):
        super(BatchNormCNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)
        self.bn1 = nn.BatchNorm2d(32)
        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)
        self.bn2 = nn.BatchNorm2d(64)
        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)
        self.bn3 = nn.BatchNorm2d(128)
        self.pool = nn.MaxPool2d(2, 2)
        self.fc1 = nn.Linear(128 * 3 * 3, 256)
        self.fc2 = nn.Linear(256, num_classes)
        self.dropout = nn.Dropout(dropout)

    def forward(self, x):
        x = self.pool(F.relu(self.bn1(self.conv1(x))))
        x = self.pool(F.relu(self.bn2(self.conv2(x))))
        x = self.pool(F.relu(self.bn3(self.conv3(x))))
        x = x.view(-1, 128 * 3 * 3)
        x = F.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.fc2(x)
        return x


class DeepCNN(nn.Module):
    def __init__(self, num_classes=11, dropout=0.3):
        super(DeepCNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)
        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)
        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)
        self.conv4 = nn.Conv2d(128, 256, 3, padding=1)
        self.pool = nn.MaxPool2d(2, 2)
        self.fc1 = nn.Linear(256 * 3 * 3, 256)
        self.fc2 = nn.Linear(256, num_classes)
        self.dropout = nn.Dropout(dropout)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = self.pool(F.relu(self.conv3(x)))
        x = F.relu(self.conv4(x))
        x = x.view(-1, 256 * 3 * 3)
        x = F.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.fc2(x)
        return x


# ===========================================================================
# TTA Transforms
# ===========================================================================

def get_tta_transforms():
    """Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ Ð½Ð°Ð±Ð¾Ñ€ Ñ‚Ñ€Ð°Ð½ÑÑ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¹ Ð´Ð»Ñ TTA"""
    base_transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.5], std=[0.5])
    ])

    # Ð›ÐµÐ³ÐºÐ¸Ðµ Ð°ÑƒÐ³Ð¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ð¸ Ð´Ð»Ñ TTA
    tta_transforms = [
        # ÐžÑ€Ð¸Ð³Ð¸Ð½Ð°Ð»
        base_transform,

        # Horizontal flip
        transforms.Compose([
            transforms.RandomHorizontalFlip(p=1.0),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.5], std=[0.5])
        ]),

        # Small rotation +5
        transforms.Compose([
            transforms.RandomRotation(degrees=(5, 5)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.5], std=[0.5])
        ]),

        # Small rotation -5
        transforms.Compose([
            transforms.RandomRotation(degrees=(-5, -5)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.5], std=[0.5])
        ]),

        # Flip + rotation
        transforms.Compose([
            transforms.RandomHorizontalFlip(p=1.0),
            transforms.RandomRotation(degrees=(5, 5)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.5], std=[0.5])
        ]),
    ]

    return tta_transforms


# ===========================================================================
# Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ…
# ===========================================================================

data_flag = 'organcmnist'
info = INFO[data_flag]
NUM_CLASSES = len(info['label'])

DataClass = getattr(medmnist, info['python_class'])

print('=' * 70)
print('TTA Ð”Ð›Ð¯ ÐžÐ Ð˜Ð“Ð˜ÐÐÐ›Ð¬ÐÐžÐ“Ðž ÐÐÐ¡ÐÐœÐ‘Ð›Ð¯ (5 ÐœÐžÐ”Ð•Ð›Ð•Ð™)')
print('=' * 70)
print()


# ===========================================================================
# Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð°Ð½ÑÐ°Ð¼Ð±Ð»Ñ
# ===========================================================================

print('Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð°Ð½ÑÐ°Ð¼Ð±Ð»Ñ (5 Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹)...')

with open('results/experiments_results/ensemble_results.json', 'r') as f:
    ensemble_config = json.load(f)

# ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ð°Ñ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ñ‹
architectures = [
    ('BatchNormCNN', BatchNormCNN),
    ('BatchNormCNN', BatchNormCNN),
    ('ResNetLikeCNN', ResNetLikeCNN),
    ('ResNetLikeCNN', ResNetLikeCNN),
    ('DeepCNN', DeepCNN),
]

models = []
for i, (arch_name, ArchClass) in enumerate(architectures, 1):
    model_path = f'results/experiments_results/ensemble_model_{i}.pth'
    model = ArchClass(num_classes=NUM_CLASSES).to(device)
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.eval()
    models.append(model)
    print(f'  âœ“ Ð—Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð° Ð¼Ð¾Ð´ÐµÐ»ÑŒ {i}: {arch_name}')

print(f'\nâœ“ Ð—Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð¾ {len(models)} Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹')
print(f'ÐžÑ€Ð¸Ð³Ð¸Ð½Ð°Ð»ÑŒÐ½Ð°Ñ Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚ÑŒ Ð°Ð½ÑÐ°Ð¼Ð±Ð»Ñ: {ensemble_config["test_ensemble_acc"]:.2f}%')
print()


# ===========================================================================
# TTA Prediction
# ===========================================================================

def predict_with_tta(models, dataset, tta_transforms, batch_size=128):
    """ÐŸÑ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ðµ Ñ TTA"""
    all_labels = []

    # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ labels
    for _, label in dataset:
        all_labels.append(label)
    all_labels = np.array(all_labels).squeeze()

    num_samples = len(dataset)
    num_classes = NUM_CLASSES
    num_tta = len(tta_transforms)

    # ÐœÐ°ÑÑÐ¸Ð² Ð´Ð»Ñ Ð½Ð°ÐºÐ¾Ð¿Ð»ÐµÐ½Ð¸Ñ Ð²ÐµÑ€Ð¾ÑÑ‚Ð½Ð¾ÑÑ‚ÐµÐ¹
    accumulated_probs = np.zeros((num_samples, num_classes))

    print(f'ÐŸÑ€Ð¸Ð¼ÐµÐ½ÐµÐ½Ð¸Ðµ {num_tta} TTA Ñ‚Ñ€Ð°Ð½ÑÑ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¹...')

    for tta_idx, transform in enumerate(tta_transforms):
        print(f'\nTTA {tta_idx + 1}/{num_tta}')

        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ dataset Ñ Ñ‚ÐµÐºÑƒÑ‰ÐµÐ¹ Ñ‚Ñ€Ð°Ð½ÑÑ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÐµÐ¹
        class TTADataset(Dataset):
            def __init__(self, base_dataset, transform):
                self.base_dataset = base_dataset
                self.transform = transform

            def __len__(self):
                return len(self.base_dataset)

            def __getitem__(self, idx):
                from PIL import Image
                data_sample = self.base_dataset[idx]
                if len(data_sample) == 2:
                    img_tensor, label = data_sample
                    img_array = img_tensor.squeeze().numpy()
                    img_array = ((img_array * 0.5 + 0.5) * 255).astype('uint8')
                    img = Image.fromarray(img_array, mode='L')
                    img = self.transform(img)
                    return img, label
                else:
                    raise ValueError(f"Unexpected data format: {type(data_sample)}")

        tta_dataset = TTADataset(dataset, transform)
        tta_loader = DataLoader(tta_dataset, batch_size=batch_size, shuffle=False)

        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ Ð¾Ñ‚ Ð²ÑÐµÑ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð´Ð»Ñ ÑÑ‚Ð¾Ð¹ TTA
        tta_probs = np.zeros((num_samples, num_classes))

        for model_idx, model in enumerate(models):
            model.eval()
            batch_start = 0

            with torch.no_grad():
                for images, _ in tqdm(tta_loader, desc=f'  Model {model_idx+1}/{len(models)}', leave=False):
                    images = images.to(device)
                    outputs = model(images)
                    probs = F.softmax(outputs, dim=1).cpu().numpy()

                    batch_size_actual = probs.shape[0]
                    tta_probs[batch_start:batch_start + batch_size_actual] += probs
                    batch_start += batch_size_actual

        # Ð£ÑÑ€ÐµÐ´Ð½ÑÐµÐ¼ Ð¿Ð¾ Ð¼Ð¾Ð´ÐµÐ»ÑÐ¼
        tta_probs /= len(models)

        # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ðº Ð¾Ð±Ñ‰ÐµÐ¼Ñƒ Ð½Ð°ÐºÐ¾Ð¿Ð»ÐµÐ½Ð¸ÑŽ
        accumulated_probs += tta_probs

    # Ð¤Ð¸Ð½Ð°Ð»ÑŒÐ½Ð¾Ðµ ÑƒÑÑ€ÐµÐ´Ð½ÐµÐ½Ð¸Ðµ Ð¿Ð¾ Ð²ÑÐµÐ¼ TTA
    final_probs = accumulated_probs / num_tta

    # ÐŸÑ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ
    predictions = np.argmax(final_probs, axis=1)
    accuracy = 100. * np.mean(predictions == all_labels)

    return accuracy, predictions, all_labels


# ===========================================================================
# Ð¢ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ
# ===========================================================================

print('Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° test dataset...')
test_transform_base = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5], std=[0.5])
])

test_dataset = DataClass(split='test', download=False, transform=test_transform_base, as_rgb=False)
print(f'Test samples: {len(test_dataset)}\n')

# Baseline (Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð°Ð½ÑÐ°Ð¼Ð±Ð»ÑŒ Ð±ÐµÐ· TTA)
baseline_acc = ensemble_config['test_ensemble_acc']
print(f'Baseline (Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð°Ð½ÑÐ°Ð¼Ð±Ð»ÑŒ): {baseline_acc:.2f}%\n')

# TTA
tta_transforms = get_tta_transforms()
print(f'ÐŸÑ€Ð¸Ð¼ÐµÐ½ÐµÐ½Ð¸Ðµ TTA Ñ {len(tta_transforms)} Ñ‚Ñ€Ð°Ð½ÑÑ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑÐ¼Ð¸...')
tta_acc, _, _ = predict_with_tta(models, test_dataset, tta_transforms)

print('\n' + '=' * 70)
print('Ð Ð•Ð—Ð£Ð›Ð¬Ð¢ÐÐ¢Ð«')
print('=' * 70)
print(f'\nBaseline (Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð°Ð½ÑÐ°Ð¼Ð±Ð»ÑŒ):  {baseline_acc:.2f}%')
print(f'Ð¡ TTA ({len(tta_transforms)} transforms):     {tta_acc:.2f}%')
print(f'Ð£Ð»ÑƒÑ‡ÑˆÐµÐ½Ð¸Ðµ:                        +{tta_acc - baseline_acc:.2f}%')

# Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²
results = {
    'num_models': len(models),
    'num_tta_transforms': len(tta_transforms),
    'baseline_acc': baseline_acc,
    'tta_acc': tta_acc,
    'improvement': tta_acc - baseline_acc,
    'note': 'TTA applied to original 5-model ensemble'
}

with open('results/experiments_results/tta_original5_results.json', 'w') as f:
    json.dump(results, f, indent=2)

print('\nâœ“ Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ñ‹: results/experiments_results/tta_original5_results.json')

print('\n' + '=' * 70)
if tta_acc >= 92.0:
    print('ðŸŽ‰ Ð¦Ð•Ð›Ð¬ Ð”ÐžÐ¡Ð¢Ð˜Ð“ÐÐ£Ð¢Ð: >=92% accuracy!')
else:
    print(f'ðŸ“Š Ð¢ÐµÐºÑƒÑ‰Ð¸Ð¹ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚: {tta_acc:.2f}% (Ñ†ÐµÐ»ÑŒ: >=92%)')
print('=' * 70)
