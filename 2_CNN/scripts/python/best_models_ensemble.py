"""
Best Models Ensemble - –≤—ã–±–æ—Ä –ª—É—á—à–∏—Ö 5 –º–æ–¥–µ–ª–µ–π –∏–∑ 10 –¥–ª—è –∞–Ω—Å–∞–º–±–ª—è

–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ –≤—ã–±–∏—Ä–∞–µ–º —Ç–æ–ø-5 –º–æ–¥–µ–ª–µ–π
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
from torchvision import transforms
import numpy as np
import json
import medmnist
from medmnist import INFO
from tqdm import tqdm


# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
if torch.cuda.is_available():
    device = torch.device('cuda')
elif torch.backends.mps.is_available():
    device = torch.device('mps')
else:
    device = torch.device('cpu')

print(f'Device: {device}\n')


# ===========================================================================
# –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏
# ===========================================================================

class ResidualBlock(nn.Module):
    def __init__(self, channels):
        super(ResidualBlock, self).__init__()
        self.conv1 = nn.Conv2d(channels, channels, 3, padding=1)
        self.bn1 = nn.BatchNorm2d(channels)
        self.conv2 = nn.Conv2d(channels, channels, 3, padding=1)
        self.bn2 = nn.BatchNorm2d(channels)

    def forward(self, x):
        residual = x
        out = F.relu(self.bn1(self.conv1(x)))
        out = self.bn2(self.conv2(out))
        out += residual
        out = F.relu(out)
        return out


class ResNetLikeCNN(nn.Module):
    def __init__(self, num_classes=11, dropout=0.3, hidden_dim=64):
        super(ResNetLikeCNN, self).__init__()
        self.conv1 = nn.Conv2d(1, hidden_dim, 3, padding=1)
        self.bn1 = nn.BatchNorm2d(hidden_dim)
        self.pool = nn.MaxPool2d(2, 2)
        self.res_block1 = ResidualBlock(hidden_dim)
        self.res_block2 = ResidualBlock(hidden_dim)
        self.conv2 = nn.Conv2d(hidden_dim, 128, 3, padding=1, stride=2)
        self.bn2 = nn.BatchNorm2d(128)
        self.global_pool = nn.AdaptiveAvgPool2d(1)
        self.fc = nn.Linear(128, num_classes)
        self.dropout = nn.Dropout(dropout)

    def forward(self, x):
        x = F.relu(self.bn1(self.conv1(x)))
        x = self.pool(x)
        x = self.res_block1(x)
        x = self.res_block2(x)
        x = F.relu(self.bn2(self.conv2(x)))
        x = self.global_pool(x)
        x = x.view(x.size(0), -1)
        x = self.dropout(x)
        x = self.fc(x)
        return x


# ===========================================================================
# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
# ===========================================================================

data_flag = 'organcmnist'
info = INFO[data_flag]
NUM_CLASSES = len(info['label'])
BATCH_SIZE = 128

test_transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5], std=[0.5])
])

DataClass = getattr(medmnist, info['python_class'])
test_dataset = DataClass(split='test', download=False, transform=test_transform, as_rgb=False)
test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)

print(f'Test samples: {len(test_dataset)}\n')


# ===========================================================================
# –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏ –≤—ã–±–æ—Ä –ª—É—á—à–∏—Ö –º–æ–¥–µ–ª–µ–π
# ===========================================================================

print('=' * 70)
print('–ê–ù–°–ê–ú–ë–õ–¨ –õ–£–ß–®–ò–• 5 –ú–û–î–ï–õ–ï–ô –ò–ó 10')
print('=' * 70)
print()

# –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
with open('results/experiments_results/ensemble_large_results.json', 'r') as f:
    large_ensemble = json.load(f)

# –°–æ—Ä—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª–∏ –ø–æ test_acc
models_info = large_ensemble['individual_models']
models_sorted = sorted(enumerate(models_info), key=lambda x: x[1]['test_acc'], reverse=True)

print('–í—Å–µ 10 –º–æ–¥–µ–ª–µ–π (–æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –ø–æ test accuracy):')
print()
for idx, (original_idx, model_info) in enumerate(models_sorted, 1):
    print(f'{idx}. [{original_idx+1}/10] {model_info["name"]:<25} Test={model_info["test_acc"]:.2f}%')

# –í—ã–±–∏—Ä–∞–µ–º —Ç–æ–ø-5
top5_indices = [original_idx for original_idx, _ in models_sorted[:5]]
print()
print('–í—ã–±—Ä–∞–Ω—ã –¢–û–ü-5 –º–æ–¥–µ–ª–µ–π:')
for rank, original_idx in enumerate(top5_indices, 1):
    model_info = models_info[original_idx]
    print(f'{rank}. –ú–æ–¥–µ–ª—å {original_idx+1}: {model_info["name"]:<25} Test={model_info["test_acc"]:.2f}%')
print()


# ===========================================================================
# –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–ø-5 –º–æ–¥–µ–ª–µ–π
# ===========================================================================

print('–ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–ø-5 –º–æ–¥–µ–ª–µ–π...')
selected_models = []

for original_idx in top5_indices:
    model_info = models_info[original_idx]
    model_path = f'results/experiments_results/ensemble_large_model_{original_idx+1}.pth'

    dropout = model_info.get('dropout', 0.3)
    hidden_dim = model_info.get('hidden_dim', 64)

    model = ResNetLikeCNN(num_classes=NUM_CLASSES, dropout=dropout, hidden_dim=hidden_dim).to(device)
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.eval()
    selected_models.append(model)
    print(f'  ‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–∞ –º–æ–¥–µ–ª—å {original_idx+1}')

print(f'\n‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(selected_models)} –º–æ–¥–µ–ª–µ–π\n')


# ===========================================================================
# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
# ===========================================================================

def get_predictions_proba(model, dataloader, device):
    """–ü–æ–ª—É—á–∏—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π"""
    model.eval()
    all_probs = []
    all_labels = []

    with torch.no_grad():
        for images, labels in tqdm(dataloader, desc='Getting predictions', leave=False):
            images = images.to(device)
            outputs = model(images)
            probs = F.softmax(outputs, dim=1)

            all_probs.append(probs.cpu().numpy())
            all_labels.append(labels.squeeze().numpy())

    return np.vstack(all_probs), np.concatenate(all_labels)


# ===========================================================================
# –ê–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–æ–ø-5
# ===========================================================================

print('–ê–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–æ–ø-5 –º–æ–¥–µ–ª–µ–π —á–µ—Ä–µ–∑ soft voting...')

all_probs_ensemble = []
all_labels = None

for i, model in enumerate(selected_models):
    print(f'Getting predictions from model {i+1}/5...')
    probs, labels = get_predictions_proba(model, test_loader, device)
    all_probs_ensemble.append(probs)
    if all_labels is None:
        all_labels = labels

# –£—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
avg_probs = np.mean(all_probs_ensemble, axis=0)
predictions = np.argmax(avg_probs, axis=1)

# –ü–æ–¥—Å—á–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç–∏
ensemble_acc = 100. * np.mean(predictions == all_labels)

print()
print('=' * 70)
print('–†–ï–ó–£–õ–¨–¢–ê–¢–´')
print('=' * 70)
print()

# –ò–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–æ–ø-5
print('–ò–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–æ–ø-5 –º–æ–¥–µ–ª–µ–π:')
for rank, original_idx in enumerate(top5_indices, 1):
    model_info = models_info[original_idx]
    print(f'  {rank}. {model_info["name"]:<25} Test={model_info["test_acc"]:.2f}%')

avg_individual = np.mean([models_info[idx]['test_acc'] for idx in top5_indices])
print(f'\n–°—Ä–µ–¥–Ω–µ–µ –ø–æ –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–º: {avg_individual:.2f}%')
print(f'–ê–Ω—Å–∞–º–±–ª—å (—Ç–æ–ø-5):          {ensemble_acc:.2f}%')
print(f'–£–ª—É—á—à–µ–Ω–∏–µ:                 +{ensemble_acc - avg_individual:.2f}%')
print()

# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
print('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ:')
print(f'  –ê–Ω—Å–∞–º–±–ª—å 5 –º–æ–¥–µ–ª–µ–π (–æ—Ä–∏–≥–∏–Ω–∞–ª):  91.16%')
print(f'  –ê–Ω—Å–∞–º–±–ª—å 10 –º–æ–¥–µ–ª–µ–π (–≤—Å–µ):      91.02%')
print(f'  –ê–Ω—Å–∞–º–±–ª—å 10 –º–æ–¥–µ–ª–µ–π + TTA:      91.13%')
print(f'  –ê–Ω—Å–∞–º–±–ª—å 5 –ª—É—á—à–∏—Ö –∏–∑ 10:        {ensemble_acc:.2f}%')
print()

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
results = {
    'selected_models_indices': [int(idx) for idx in top5_indices],
    'selected_models': [models_info[idx] for idx in top5_indices],
    'avg_individual': avg_individual,
    'ensemble_acc': ensemble_acc,
    'improvement': ensemble_acc - avg_individual
}

with open('results/experiments_results/best5_ensemble_results.json', 'w') as f:
    json.dump(results, f, indent=2)

print('‚úì –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: results/experiments_results/best5_ensemble_results.json')
print()

if ensemble_acc >= 92.0:
    print('=' * 70)
    print('üéâ –¶–ï–õ–¨ –î–û–°–¢–ò–ì–ù–£–¢–ê: >=92% accuracy!')
    print('=' * 70)
else:
    print('=' * 70)
    print(f'üìä –¢–µ–∫—É—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {ensemble_acc:.2f}% (—Ü–µ–ª—å: >=92%)')
    print('=' * 70)
