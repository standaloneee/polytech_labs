"""
Test-Time Augmentation (TTA) - ÑƒÑÑ€ÐµÐ´Ð½ÐµÐ½Ð¸Ðµ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ð¹ Ñ Ð°ÑƒÐ³Ð¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸ÐµÐ¹

ÐŸÑ€Ð¸Ð¼ÐµÐ½ÑÐµÑ‚ Ð»ÐµÐ³ÐºÑƒÑŽ Ð°ÑƒÐ³Ð¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸ÑŽ Ð¿Ñ€Ð¸ Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ð¸ Ð¸ ÑƒÑÑ€ÐµÐ´Ð½ÑÐµÑ‚ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹
Ð´Ð»Ñ Ð¿Ð¾Ð²Ñ‹ÑˆÐµÐ½Ð¸Ñ Ñ€Ð¾Ð±Ð°ÑÑ‚Ð½Ð¾ÑÑ‚Ð¸ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ð¹
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms
import numpy as np
import json
import medmnist
from medmnist import INFO
from tqdm import tqdm
import os


# ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ ÑƒÑÑ‚Ñ€Ð¾Ð¹ÑÑ‚Ð²Ð°
if torch.cuda.is_available():
    device = torch.device('cuda')
elif torch.backends.mps.is_available():
    device = torch.device('mps')
else:
    device = torch.device('cpu')

print(f'Device: {device}\n')


# ===========================================================================
# ÐÑ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð° Ð¼Ð¾Ð´ÐµÐ»Ð¸
# ===========================================================================

class ResidualBlock(nn.Module):
    def __init__(self, channels):
        super(ResidualBlock, self).__init__()
        self.conv1 = nn.Conv2d(channels, channels, 3, padding=1)
        self.bn1 = nn.BatchNorm2d(channels)
        self.conv2 = nn.Conv2d(channels, channels, 3, padding=1)
        self.bn2 = nn.BatchNorm2d(channels)

    def forward(self, x):
        residual = x
        out = F.relu(self.bn1(self.conv1(x)))
        out = self.bn2(self.conv2(out))
        out += residual
        out = F.relu(out)
        return out


class ResNetLikeCNN(nn.Module):
    def __init__(self, num_classes=11, dropout=0.3, hidden_dim=64):
        super(ResNetLikeCNN, self).__init__()
        self.conv1 = nn.Conv2d(1, hidden_dim, 3, padding=1)
        self.bn1 = nn.BatchNorm2d(hidden_dim)
        self.pool = nn.MaxPool2d(2, 2)
        self.res_block1 = ResidualBlock(hidden_dim)
        self.res_block2 = ResidualBlock(hidden_dim)
        self.conv2 = nn.Conv2d(hidden_dim, 128, 3, padding=1, stride=2)
        self.bn2 = nn.BatchNorm2d(128)
        self.global_pool = nn.AdaptiveAvgPool2d(1)
        self.fc = nn.Linear(128, num_classes)
        self.dropout = nn.Dropout(dropout)

    def forward(self, x):
        x = F.relu(self.bn1(self.conv1(x)))
        x = self.pool(x)
        x = self.res_block1(x)
        x = self.res_block2(x)
        x = F.relu(self.bn2(self.conv2(x)))
        x = self.global_pool(x)
        x = x.view(x.size(0), -1)
        x = self.dropout(x)
        x = self.fc(x)
        return x


# ===========================================================================
# TTA Transforms
# ===========================================================================

def get_tta_transforms():
    """Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ Ð½Ð°Ð±Ð¾Ñ€ Ñ‚Ñ€Ð°Ð½ÑÑ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¹ Ð´Ð»Ñ TTA"""
    base_transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.5], std=[0.5])
    ])

    # Ð›ÐµÐ³ÐºÐ¸Ðµ Ð°ÑƒÐ³Ð¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ð¸ Ð´Ð»Ñ TTA
    tta_transforms = [
        # ÐžÑ€Ð¸Ð³Ð¸Ð½Ð°Ð»
        base_transform,

        # Horizontal flip
        transforms.Compose([
            transforms.RandomHorizontalFlip(p=1.0),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.5], std=[0.5])
        ]),

        # Small rotation +5
        transforms.Compose([
            transforms.RandomRotation(degrees=(5, 5)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.5], std=[0.5])
        ]),

        # Small rotation -5
        transforms.Compose([
            transforms.RandomRotation(degrees=(-5, -5)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.5], std=[0.5])
        ]),

        # Flip + rotation
        transforms.Compose([
            transforms.RandomHorizontalFlip(p=1.0),
            transforms.RandomRotation(degrees=(5, 5)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.5], std=[0.5])
        ]),
    ]

    return tta_transforms


# ===========================================================================
# Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ…
# ===========================================================================

data_flag = 'organcmnist'
info = INFO[data_flag]
NUM_CLASSES = len(info['label'])

DataClass = getattr(medmnist, info['python_class'])

print('=' * 70)
print('TEST-TIME AUGMENTATION (TTA)')
print('=' * 70)
print()


# ===========================================================================
# Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹
# ===========================================================================

print('Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹...')

model_files = []
ensemble_results_file = None

# ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÐºÐ°ÐºÐ¾Ð¹ Ð°Ð½ÑÐ°Ð¼Ð±Ð»ÑŒ Ð´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½ (Ð¿Ñ€ÐµÐ´Ð¿Ð¾Ñ‡Ð¸Ñ‚Ð°ÐµÐ¼ Ð±Ð¾Ð»ÑŒÑˆÐ¾Ð¹)
if os.path.exists('results/experiments_results/ensemble_large_results.json'):
    ensemble_results_file = 'results/experiments_results/ensemble_large_results.json'
    model_pattern = 'results/experiments_results/ensemble_large_model_{}.pth'
    print('Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ ÑƒÐ²ÐµÐ»Ð¸Ñ‡ÐµÐ½Ð½Ñ‹Ð¹ Ð°Ð½ÑÐ°Ð¼Ð±Ð»ÑŒ (10 Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹)')
elif os.path.exists('results/experiments_results/ensemble_results.json'):
    ensemble_results_file = 'results/experiments_results/ensemble_results.json'
    model_pattern = 'results/experiments_results/ensemble_model_{}.pth'
    print('Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð±Ð°Ð·Ð¾Ð²Ñ‹Ð¹ Ð°Ð½ÑÐ°Ð¼Ð±Ð»ÑŒ (5 Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹)')
else:
    print('ÐžÑˆÐ¸Ð±ÐºÐ°: ÐÐµ Ð½Ð°Ð¹Ð´ÐµÐ½Ñ‹ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð°Ð½ÑÐ°Ð¼Ð±Ð»Ñ!')
    exit(1)

# Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸ÑŽ
with open(ensemble_results_file, 'r') as f:
    ensemble_config = json.load(f)

num_models = ensemble_config['num_models']

# Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð¼Ð¾Ð´ÐµÐ»Ð¸
models = []
for i in range(1, num_models + 1):
    model_path = model_pattern.format(i)

    if 'individual_models' in ensemble_config and len(ensemble_config['individual_models']) >= i:
        model_info = ensemble_config['individual_models'][i-1]
        dropout = model_info.get('dropout', 0.3)
        hidden_dim = model_info.get('hidden_dim', 64)
    else:
        dropout = 0.3
        hidden_dim = 64

    model = ResNetLikeCNN(num_classes=NUM_CLASSES, dropout=dropout, hidden_dim=hidden_dim).to(device)
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.eval()
    models.append(model)

print(f'âœ“ Ð—Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð¾ {len(models)} Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹\n')


# ===========================================================================
# TTA Prediction
# ===========================================================================

def predict_with_tta(models, dataset, tta_transforms, batch_size=128):
    """ÐŸÑ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ðµ Ñ TTA"""
    all_labels = []

    # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ labels
    for _, label in dataset:
        all_labels.append(label)
    all_labels = np.array(all_labels).squeeze()

    num_samples = len(dataset)
    num_classes = NUM_CLASSES
    num_tta = len(tta_transforms)

    # ÐœÐ°ÑÑÐ¸Ð² Ð´Ð»Ñ Ð½Ð°ÐºÐ¾Ð¿Ð»ÐµÐ½Ð¸Ñ Ð²ÐµÑ€Ð¾ÑÑ‚Ð½Ð¾ÑÑ‚ÐµÐ¹
    accumulated_probs = np.zeros((num_samples, num_classes))

    print(f'ÐŸÑ€Ð¸Ð¼ÐµÐ½ÐµÐ½Ð¸Ðµ {num_tta} TTA Ñ‚Ñ€Ð°Ð½ÑÑ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¹...')

    for tta_idx, transform in enumerate(tta_transforms):
        print(f'\nTTA {tta_idx + 1}/{num_tta}')

        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ dataset Ñ Ñ‚ÐµÐºÑƒÑ‰ÐµÐ¹ Ñ‚Ñ€Ð°Ð½ÑÑ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÐµÐ¹
        class TTADataset(Dataset):
            def __init__(self, base_dataset, transform):
                self.base_dataset = base_dataset
                self.transform = transform

            def __len__(self):
                return len(self.base_dataset)

            def __getitem__(self, idx):
                # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ PIL Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ð¸Ð· Ð±Ð°Ð·Ð¾Ð²Ð¾Ð³Ð¾ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ð°
                # OrganCMNIST Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ (img, label) Ð³Ð´Ðµ img - PIL Image
                from PIL import Image
                # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ ÑÑ‹Ñ€Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ
                data_sample = self.base_dataset[idx]
                if len(data_sample) == 2:
                    img_tensor, label = data_sample
                    # ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·ÑƒÐµÐ¼ Ñ‚ÐµÐ½Ð·Ð¾Ñ€ Ð¾Ð±Ñ€Ð°Ñ‚Ð½Ð¾ Ð² PIL Image Ð´Ð»Ñ Ñ‚Ñ€Ð°Ð½ÑÑ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¹
                    img_array = img_tensor.squeeze().numpy()
                    img_array = ((img_array * 0.5 + 0.5) * 255).astype('uint8')  # Ð´ÐµÐ½Ð¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ
                    img = Image.fromarray(img_array, mode='L')
                    # ÐŸÑ€Ð¸Ð¼ÐµÐ½ÑÐµÐ¼ Ñ‚Ñ€Ð°Ð½ÑÑ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ
                    img = self.transform(img)
                    return img, label
                else:
                    raise ValueError(f"Unexpected data format: {type(data_sample)}")

        tta_dataset = TTADataset(dataset, transform)
        tta_loader = DataLoader(tta_dataset, batch_size=batch_size, shuffle=False)

        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ Ð¾Ñ‚ Ð²ÑÐµÑ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð´Ð»Ñ ÑÑ‚Ð¾Ð¹ TTA
        tta_probs = np.zeros((num_samples, num_classes))
        sample_idx = 0

        for model_idx, model in enumerate(models):
            model.eval()
            batch_start = 0

            with torch.no_grad():
                for images, _ in tqdm(tta_loader, desc=f'  Model {model_idx+1}/{len(models)}', leave=False):
                    images = images.to(device)
                    outputs = model(images)
                    probs = F.softmax(outputs, dim=1).cpu().numpy()

                    batch_size_actual = probs.shape[0]
                    tta_probs[batch_start:batch_start + batch_size_actual] += probs
                    batch_start += batch_size_actual

        # Ð£ÑÑ€ÐµÐ´Ð½ÑÐµÐ¼ Ð¿Ð¾ Ð¼Ð¾Ð´ÐµÐ»ÑÐ¼
        tta_probs /= len(models)

        # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ðº Ð¾Ð±Ñ‰ÐµÐ¼Ñƒ Ð½Ð°ÐºÐ¾Ð¿Ð»ÐµÐ½Ð¸ÑŽ
        accumulated_probs += tta_probs

    # Ð¤Ð¸Ð½Ð°Ð»ÑŒÐ½Ð¾Ðµ ÑƒÑÑ€ÐµÐ´Ð½ÐµÐ½Ð¸Ðµ Ð¿Ð¾ Ð²ÑÐµÐ¼ TTA
    final_probs = accumulated_probs / num_tta

    # ÐŸÑ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ
    predictions = np.argmax(final_probs, axis=1)
    accuracy = 100. * np.mean(predictions == all_labels)

    return accuracy, predictions, all_labels


# ===========================================================================
# Ð¢ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ
# ===========================================================================

print('Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° test dataset...')
test_transform_base = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5], std=[0.5])
])

test_dataset = DataClass(split='test', download=False, transform=test_transform_base, as_rgb=False)
print(f'Test samples: {len(test_dataset)}\n')

# Baseline (Ð±ÐµÐ· TTA)
print('Baseline (Ð±ÐµÐ· TTA)...')
test_loader_baseline = DataLoader(test_dataset, batch_size=128, shuffle=False)

baseline_probs = np.zeros((len(test_dataset), NUM_CLASSES))
batch_start = 0

for model in models:
    model.eval()
    batch_idx = 0

    with torch.no_grad():
        for images, _ in tqdm(test_loader_baseline, desc='Baseline', leave=False):
            images = images.to(device)
            outputs = model(images)
            probs = F.softmax(outputs, dim=1).cpu().numpy()

            batch_size = probs.shape[0]
            baseline_probs[batch_idx:batch_idx + batch_size] += probs
            batch_idx += batch_size

baseline_probs /= len(models)
baseline_predictions = np.argmax(baseline_probs, axis=1)

# ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ labels
test_labels = []
for _, label in test_dataset:
    test_labels.append(label)
test_labels = np.array(test_labels).squeeze()

baseline_acc = 100. * np.mean(baseline_predictions == test_labels)
print(f'Baseline Accuracy: {baseline_acc:.2f}%\n')

# TTA
tta_transforms = get_tta_transforms()
print(f'ÐŸÑ€Ð¸Ð¼ÐµÐ½ÐµÐ½Ð¸Ðµ TTA Ñ {len(tta_transforms)} Ñ‚Ñ€Ð°Ð½ÑÑ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑÐ¼Ð¸...')
tta_acc, _, _ = predict_with_tta(models, test_dataset, tta_transforms)

print('\n' + '=' * 70)
print('Ð Ð•Ð—Ð£Ð›Ð¬Ð¢ÐÐ¢Ð«')
print('=' * 70)
print(f'\nBaseline (Ð±ÐµÐ· TTA):      {baseline_acc:.2f}%')
print(f'Ð¡ TTA ({len(tta_transforms)} transforms): {tta_acc:.2f}%')
print(f'Ð£Ð»ÑƒÑ‡ÑˆÐµÐ½Ð¸Ðµ:               +{tta_acc - baseline_acc:.2f}%')

# Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²
results = {
    'num_models': len(models),
    'num_tta_transforms': len(tta_transforms),
    'baseline_acc': baseline_acc,
    'tta_acc': tta_acc,
    'improvement': tta_acc - baseline_acc
}

with open('results/experiments_results/tta_results.json', 'w') as f:
    json.dump(results, f, indent=2)

print('\nâœ“ Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ñ‹: results/experiments_results/tta_results.json')

print('\n' + '=' * 70)
if tta_acc > 92.0:
    print('ðŸŽ‰ Ð¦Ð•Ð›Ð¬ Ð”ÐžÐ¡Ð¢Ð˜Ð“ÐÐ£Ð¢Ð: >92% accuracy!')
else:
    print(f'ðŸ“Š Ð¢ÐµÐºÑƒÑ‰Ð¸Ð¹ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚: {tta_acc:.2f}% (Ñ†ÐµÐ»ÑŒ: >92%)')
print('=' * 70)
