{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Классификация медицинских изображений с использованием многослойного перцептрона\n",
    "\n",
    "## Аннотация\n",
    "\n",
    "В данной работе исследуется применение многослойного перцептрона (MLP) для задачи классификации медицинских изображений органов из датасета OrganCMNIST. Проведен систематический анализ влияния различных гиперпараметров на качество модели, включая архитектуру сети, методы регуляризации, функции активации и параметры оптимизации. Выполнено 40 экспериментов в три раунда: базовые эксперименты (20 эпох), продвинутые эксперименты (40-50 эпох) и ансамблирование моделей. Достигнута точность классификации 80.83% на тестовой выборке, что представляет улучшение на 5.99% по сравнению с базовой моделью.\n",
    "\n",
    "**Ключевые слова:** многослойный перцептрон, классификация изображений, медицинские данные, регуляризация, batch normalization, ансамблирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Введение\n",
    "\n",
    "### 1.1 Постановка задачи\n",
    "\n",
    "Целью данного исследования является разработка и оптимизация многослойного перцептрона для задачи многоклассовой классификации медицинских изображений органов.\n",
    "\n",
    "### 1.2 Датасет\n",
    "\n",
    "Используется датасет OrganCMNIST из коллекции MedMNIST [1], содержащий медицинские изображения 11 типов органов:\n",
    "\n",
    "- **Классы:** bladder, femur (left/right), heart, kidney (left/right), liver, lung (left/right), pancreas, spleen\n",
    "- **Размерность изображений:** 28×28 пикселей (grayscale)\n",
    "- **Разбиение данных:**\n",
    "  - Обучающая выборка: 12,975 изображений\n",
    "  - Валидационная выборка: 2,392 изображения\n",
    "  - Тестовая выборка: 8,216 изображений\n",
    "\n",
    "### 1.3 Задачи исследования\n",
    "\n",
    "1. Разработка базовой архитектуры MLP\n",
    "2. Систематическое исследование влияния гиперпараметров\n",
    "3. Применение методов регуляризации для снижения переобучения\n",
    "4. Оценка эффективности ансамблирования моделей\n",
    "5. Достижение максимальной точности классификации в рамках архитектуры MLP\n",
    "\n",
    "### 1.4 Воспроизводимость\n",
    "\n",
    "Для обеспечения воспроизводимости результатов все эксперименты выполнены с фиксированным random seed (SEED=42), детерминистическими настройками PyTorch и полным документированием конфигураций."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Методология\n",
    "\n",
    "### 2.1 Архитектура модели\n",
    "\n",
    "Многослойный перцептрон представляет собой полносвязную нейронную сеть следующей структуры:\n",
    "\n",
    "$$f(x) = W_L \\cdot \\sigma(W_{L-1} \\cdot \\sigma(\\ldots \\sigma(W_1 \\cdot x + b_1)\\ldots) + b_{L-1}) + b_L$$\n",
    "\n",
    "где:\n",
    "- $x \\in \\mathbb{R}^{784}$ - входной вектор (развернутое изображение 28×28)\n",
    "- $W_i$ - матрица весов слоя $i$\n",
    "- $b_i$ - вектор смещений слоя $i$\n",
    "- $\\sigma$ - функция активации\n",
    "- $L$ - количество слоев\n",
    "\n",
    "### 2.2 Функция потерь\n",
    "\n",
    "Для многоклассовой классификации используется функция кросс-энтропии:\n",
    "\n",
    "$$\\mathcal{L}(y, \\hat{y}) = -\\sum_{i=1}^{C} y_i \\log(\\hat{y}_i)$$\n",
    "\n",
    "где $C=11$ - количество классов, $y$ - истинная метка, $\\hat{y}$ - предсказанное распределение вероятностей.\n",
    "\n",
    "### 2.3 Оптимизация\n",
    "\n",
    "Используется оптимизатор Adam [2] с параметрами:\n",
    "- Learning rate: $\\alpha = 0.001$\n",
    "- Параметры моментов: $\\beta_1 = 0.9$, $\\beta_2 = 0.999$\n",
    "- Batch size: 128\n",
    "\n",
    "### 2.4 Метрики оценки\n",
    "\n",
    "**Accuracy (точность):**\n",
    "$$\\text{Accuracy} = \\frac{1}{N} \\sum_{i=1}^{N} \\mathbb{1}(\\arg\\max(\\hat{y}_i) = y_i)$$\n",
    "\n",
    "**Loss (функция потерь):** Среднее значение кросс-энтропии по выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Magic command для отображения графиков в Jupyter Notebook\n%matplotlib inline\n\n# Импорт необходимых библиотек\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport medmnist\nfrom medmnist import INFO, OrganCMNIST\nfrom torchvision import transforms\nimport random\nimport pandas as pd\nimport json\n\n# Параметры воспроизводимости\nSEED = 42\n\ndef set_seed(seed=SEED):\n    \"\"\"\n    Установка seed для обеспечения воспроизводимости результатов.\n    \n    Parameters:\n    -----------\n    seed : int\n        Значение random seed\n    \"\"\"\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nset_seed()\n\n# Определение вычислительного устройства\nif torch.cuda.is_available():\n    device = torch.device('cuda')\n    print(f'Используется: CUDA ({torch.cuda.get_device_name(0)})')\nelif torch.backends.mps.is_available():\n    device = torch.device('mps')\n    print('Используется: Apple Metal Performance Shaders (MPS)')\nelse:\n    device = torch.device('cpu')\n    print('Используется: CPU')\n\nprint(f'Версия PyTorch: {torch.__version__}')\nprint(f'Версия MedMNIST: {medmnist.__version__}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Загрузка и предобработка данных\n",
    "\n",
    "### 3.1 Характеристики датасета\n",
    "\n",
    "Датасет OrganCMNIST получен из 3D компьютерных томографий (CT) и представляет собой осевые срезы различных органов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка метаинформации о датасете\n",
    "data_flag = 'organcmnist'\n",
    "info = INFO[data_flag]\n",
    "\n",
    "print(f\"Задача: {info['task']}\")\n",
    "print(f\"Количество классов: {len(info['label'])}\")\n",
    "print(f\"Метки классов: {info['label']}\")\n",
    "print(f\"Размерность: {info['n_channels']} канал(а), 28×28 пикселей\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Предобработка\n",
    "\n",
    "Применяется стандартная нормализация интенсивностей пикселей:\n",
    "\n",
    "$$x_{\\text{norm}} = \\frac{x - \\mu}{\\sigma}$$\n",
    "\n",
    "где $\\mu = 0.5$, $\\sigma = 0.5$ для приведения значений к диапазону $[-1, 1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение трансформаций\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "# Загрузка разбиений датасета\n",
    "# Параметр download=False предполагает предварительно загруженный датасет в ~/.medmnist/\n",
    "train_dataset = OrganCMNIST(split='train', transform=transform, download=False)\n",
    "val_dataset = OrganCMNIST(split='val', transform=transform, download=False)\n",
    "test_dataset = OrganCMNIST(split='test', transform=transform, download=False)\n",
    "\n",
    "print(f\"Размер обучающей выборки: {len(train_dataset)}\")\n",
    "print(f\"Размер валидационной выборки: {len(val_dataset)}\")\n",
    "print(f\"Размер тестовой выборки: {len(test_dataset)}\")\n",
    "\n",
    "# Создание DataLoader для батч-обработки\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Визуализация образцов\n",
    "\n",
    "Анализ распределения классов и визуальная оценка качества данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация случайных образцов из каждого класса\n",
    "fig, axes = plt.subplots(3, 4, figsize=(12, 9))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(11):\n",
    "    # Поиск образца класса i\n",
    "    for j, (img, label) in enumerate(train_dataset):\n",
    "        if label.item() == i:\n",
    "            axes[i].imshow(img.squeeze(), cmap='gray')\n",
    "            axes[i].set_title(f'Класс {i}: {info[\"label\"][str(i)]}')\n",
    "            axes[i].axis('off')\n",
    "            break\n",
    "\n",
    "# Удаление лишней подграфики\n",
    "axes[11].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Анализ распределения классов в обучающей выборке\n",
    "labels = [label.item() for _, label in train_dataset]\n",
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "\n",
    "print(\"\\nРаспределение классов в обучающей выборке:\")\n",
    "for cls, count in zip(unique, counts):\n",
    "    print(f\"  Класс {cls} ({info['label'][str(cls)]}): {count} образцов ({count/len(labels)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Реализация модели\n",
    "\n",
    "### 4.1 Архитектура MLP\n",
    "\n",
    "Реализована гибкая архитектура многослойного перцептрона с поддержкой:\n",
    "- Произвольного количества скрытых слоев\n",
    "- Batch Normalization [3]\n",
    "- Dropout регуляризации [4]\n",
    "- Различных функций активации (ReLU, LeakyReLU, ELU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Многослойный перцептрон для классификации изображений.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    input_size : int\n",
    "        Размерность входного вектора (по умолчанию 784 для 28×28 изображений)\n",
    "    hidden_sizes : list of int\n",
    "        Размеры скрытых слоев\n",
    "    num_classes : int\n",
    "        Количество классов для классификации\n",
    "    dropout : float\n",
    "        Вероятность dropout (0 - без dropout)\n",
    "    use_batch_norm : bool\n",
    "        Использовать ли batch normalization\n",
    "    activation : str\n",
    "        Тип функции активации ('relu', 'leaky_relu', 'elu')\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_size=784, hidden_sizes=[128, 64], num_classes=11,\n",
    "                 dropout=0.0, use_batch_norm=False, activation='relu'):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        \n",
    "        # Выбор функции активации\n",
    "        activation_functions = {\n",
    "            'relu': nn.ReLU(),\n",
    "            'leaky_relu': nn.LeakyReLU(),\n",
    "            'elu': nn.ELU()\n",
    "        }\n",
    "        self.activation = activation_functions.get(activation, nn.ReLU())\n",
    "        \n",
    "        # Построение последовательности слоев\n",
    "        layers = []\n",
    "        prev_size = input_size\n",
    "        \n",
    "        for hidden_size in hidden_sizes:\n",
    "            # Линейный слой\n",
    "            layers.append(nn.Linear(prev_size, hidden_size))\n",
    "            \n",
    "            # Batch normalization (опционально)\n",
    "            if use_batch_norm:\n",
    "                layers.append(nn.BatchNorm1d(hidden_size))\n",
    "            \n",
    "            # Функция активации\n",
    "            layers.append(self.activation)\n",
    "            \n",
    "            # Dropout регуляризация (опционально)\n",
    "            if dropout > 0:\n",
    "                layers.append(nn.Dropout(dropout))\n",
    "            \n",
    "            prev_size = hidden_size\n",
    "        \n",
    "        # Выходной слой\n",
    "        layers.append(nn.Linear(prev_size, num_classes))\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "        \n",
    "        # Инициализация весов (Kaiming initialization для ReLU-подобных активаций)\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Инициализация весов модели методом Kaiming.\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Прямое распространение.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        x : torch.Tensor\n",
    "            Входной тензор формы (batch_size, channels, height, width)\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        torch.Tensor\n",
    "            Выходной тензор логитов формы (batch_size, num_classes)\n",
    "        \"\"\"\n",
    "        # Преобразование 2D изображения в вектор\n",
    "        x = x.view(-1, self.input_size)\n",
    "        return self.model(x)\n",
    "    \n",
    "    def count_parameters(self):\n",
    "        \"\"\"Подсчет количества обучаемых параметров модели.\"\"\"\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Функции обучения и оценки\n",
    "\n",
    "Реализованы стандартные процедуры обучения с использованием алгоритма обратного распространения ошибки и оценки модели на валидационной и тестовой выборках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"\n",
    "    Обучение модели на одной эпохе.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : nn.Module\n",
    "        Обучаемая модель\n",
    "    dataloader : DataLoader\n",
    "        Загрузчик данных\n",
    "    criterion : nn.Module\n",
    "        Функция потерь\n",
    "    optimizer : torch.optim.Optimizer\n",
    "        Оптимизатор\n",
    "    device : torch.device\n",
    "        Устройство вычислений\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        (средние потери, точность в %)\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in tqdm(dataloader, desc='Обучение', leave=False):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device).squeeze().long()\n",
    "        \n",
    "        # Обнуление градиентов\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Прямое распространение\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Обратное распространение и оптимизация\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Накопление статистики\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_acc = 100.0 * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    \"\"\"\n",
    "    Оценка модели на валидационной/тестовой выборке.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : nn.Module\n",
    "        Оцениваемая модель\n",
    "    dataloader : DataLoader\n",
    "        Загрузчик данных\n",
    "    criterion : nn.Module\n",
    "        Функция потерь\n",
    "    device : torch.device\n",
    "        Устройство вычислений\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        (средние потери, точность в %)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device).squeeze().long()\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_acc = 100.0 * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, \n",
    "                num_epochs, device, scheduler=None):\n",
    "    \"\"\"\n",
    "    Полный цикл обучения модели.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : nn.Module\n",
    "        Обучаемая модель\n",
    "    train_loader : DataLoader\n",
    "        Загрузчик обучающих данных\n",
    "    val_loader : DataLoader\n",
    "        Загрузчик валидационных данных\n",
    "    criterion : nn.Module\n",
    "        Функция потерь\n",
    "    optimizer : torch.optim.Optimizer\n",
    "        Оптимизатор\n",
    "    num_epochs : int\n",
    "        Количество эпох обучения\n",
    "    device : torch.device\n",
    "        Устройство вычислений\n",
    "    scheduler : torch.optim.lr_scheduler, optional\n",
    "        Планировщик learning rate\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        (история обучения, лучшая валидационная точность)\n",
    "    \"\"\"\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': []\n",
    "    }\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'\\nЭпоха {epoch+1}/{num_epochs}')\n",
    "        print('-' * 40)\n",
    "        \n",
    "        # Обучение\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        \n",
    "        # Валидация\n",
    "        val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "        \n",
    "        # Обновление learning rate (если используется scheduler)\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        \n",
    "        # Сохранение истории\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        # Вывод метрик\n",
    "        print(f'Train - Loss: {train_loss:.4f}, Accuracy: {train_acc:.2f}%')\n",
    "        print(f'Val   - Loss: {val_loss:.4f}, Accuracy: {val_acc:.2f}%')\n",
    "        \n",
    "        # Отслеживание лучшей модели\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            print(f'Новая лучшая валидационная точность: {best_val_acc:.2f}%')\n",
    "    \n",
    "    return history, best_val_acc\n",
    "\n",
    "\n",
    "def plot_training_history(history, title='История обучения'):\n",
    "    \"\"\"\n",
    "    Визуализация истории обучения модели.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    history : dict\n",
    "        Словарь с метриками обучения\n",
    "    title : str\n",
    "        Заголовок графика\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "    \n",
    "    # График потерь\n",
    "    ax1.plot(epochs, history['train_loss'], 'b-o', label='Train', markersize=4)\n",
    "    ax1.plot(epochs, history['val_loss'], 'r-s', label='Validation', markersize=4)\n",
    "    ax1.set_xlabel('Эпоха')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title('Функция потерь')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # График точности\n",
    "    ax2.plot(epochs, history['train_acc'], 'b-o', label='Train', markersize=4)\n",
    "    ax2.plot(epochs, history['val_acc'], 'r-s', label='Validation', markersize=4)\n",
    "    ax2.set_xlabel('Эпоха')\n",
    "    ax2.set_ylabel('Accuracy (%)')\n",
    "    ax2.set_title('Точность классификации')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle(title, fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Baseline эксперимент\n",
    "\n",
    "### 5.1 Конфигурация\n",
    "\n",
    "Базовая модель служит точкой отсчета для оценки эффективности последующих улучшений. Конфигурация baseline:\n",
    "\n",
    "- **Архитектура:** [784] → [128] → [64] → [11]\n",
    "- **Функция активации:** ReLU\n",
    "- **Регуляризация:** отсутствует (dropout=0, weight_decay=0)\n",
    "- **Batch Normalization:** не используется\n",
    "- **Оптимизатор:** Adam (lr=0.001)\n",
    "- **Количество эпох:** 20\n",
    "- **Batch size:** 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры обучения\n",
    "NUM_EPOCHS = 20\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Инициализация baseline модели\n",
    "set_seed()  # Сброс seed для воспроизводимости\n",
    "\n",
    "baseline_model = MLP(\n",
    "    input_size=784,\n",
    "    hidden_sizes=[128, 64],\n",
    "    num_classes=11,\n",
    "    dropout=0.0,\n",
    "    use_batch_norm=False,\n",
    "    activation='relu'\n",
    ").to(device)\n",
    "\n",
    "print(f\"Архитектура baseline модели:\")\n",
    "print(baseline_model)\n",
    "print(f\"\\nОбщее количество параметров: {baseline_model.count_parameters():,}\")\n",
    "\n",
    "# Определение функции потерь и оптимизатора\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(baseline_model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Обучение модели\n",
    "print(f\"\\nНачало обучения baseline модели ({NUM_EPOCHS} эпох)...\")\n",
    "baseline_history, baseline_best_val_acc = train_model(\n",
    "    baseline_model, \n",
    "    train_loader, \n",
    "    val_loader, \n",
    "    criterion, \n",
    "    optimizer,\n",
    "    NUM_EPOCHS, \n",
    "    device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Результаты baseline\n",
    "\n",
    "Анализ производительности базовой модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оценка на тестовой выборке\n",
    "baseline_test_loss, baseline_test_acc = evaluate(baseline_model, test_loader, criterion, device)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"РЕЗУЛЬТАТЫ BASELINE МОДЕЛИ\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Валидационная точность (лучшая): {baseline_best_val_acc:.2f}%\")\n",
    "print(f\"Тестовая потеря: {baseline_test_loss:.4f}\")\n",
    "print(f\"Тестовая точность: {baseline_test_acc:.2f}%\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Визуализация истории обучения\n",
    "plot_training_history(baseline_history, 'Baseline модель')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Анализ baseline\n",
    "\n",
    "**Наблюдения:**\n",
    "\n",
    "1. **Переобучение:** Наблюдается значительный разрыв между точностью на обучающей (~95-99%) и тестовой (~75%) выборках, что указывает на переобучение модели.\n",
    "\n",
    "2. **Базовая точность:** Достигнута точность 74.84% на тестовой выборке, что служит отправной точкой для дальнейших улучшений.\n",
    "\n",
    "3. **Необходимость регуляризации:** Отсутствие методов регуляризации приводит к чрезмерному запоминанию обучающих данных и плохой генерализации.\n",
    "\n",
    "**Гипотезы для улучшения:**\n",
    "- Применение Dropout регуляризации\n",
    "- Использование Batch Normalization\n",
    "- L2 регуляризация (weight decay)\n",
    "- Изменение архитектуры (глубина/ширина)\n",
    "- Подбор оптимального learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Систематическое исследование гиперпараметров\n",
    "\n",
    "### 6.1 Методология экспериментов\n",
    "\n",
    "Проведено три раунда экспериментов:\n",
    "\n",
    "**Раунд 1: Базовые эксперименты (20 эпох)**\n",
    "- 24 конфигурации\n",
    "- Исследование: архитектура, регуляризация, batch normalization, функции активации, learning rate\n",
    "\n",
    "**Раунд 2: Продвинутые эксперименты (40-50 эпох)**\n",
    "- 11 конфигураций\n",
    "- Глубокие архитектуры, усиленная регуляризация, продвинутые техники\n",
    "\n",
    "**Раунд 3: Ансамблирование**\n",
    "- 5 лучших моделей с различными random seeds\n",
    "- Soft voting (усреднение вероятностей)\n",
    "\n",
    "Результаты всех экспериментов сохранены в JSON-файлах и загружаются для анализа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка результатов базовых экспериментов\n",
    "with open('../results/experiments_results/all_experiments.json', 'r') as f:\n",
    "    basic_experiments = json.load(f)\n",
    "\n",
    "print(f\"Загружено базовых экспериментов: {len(basic_experiments['experiments'])}\")\n",
    "print(f\"Дата выполнения: {basic_experiments['timestamp']}\")\n",
    "\n",
    "# Загрузка результатов продвинутых экспериментов\n",
    "with open('../results/experiments_results/advanced_experiments.json', 'r') as f:\n",
    "    advanced_experiments = json.load(f)\n",
    "\n",
    "print(f\"Загружено продвинутых экспериментов: {len(advanced_experiments['experiments'])}\")\n",
    "print(f\"Дата выполнения: {advanced_experiments['timestamp']}\")\n",
    "\n",
    "# Загрузка результатов ансамблирования\n",
    "with open('../results/experiments_results/ensemble_results.json', 'r') as f:\n",
    "    ensemble_results = json.load(f)\n",
    "\n",
    "print(f\"Загружено индивидуальных моделей в ансамбле: {len(ensemble_results['individual_models'])}\")\n",
    "print(f\"Точность ансамбля: {ensemble_results['ensemble_test_acc']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Раунд 1: Базовые эксперименты\n",
    "\n",
    "Анализ результатов 24 базовых экспериментов (20 эпох обучения)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание DataFrame для анализа\n",
    "basic_df = pd.DataFrame([\n",
    "    {\n",
    "        'Эксперимент': exp['experiment_name'],\n",
    "        'Val Acc (%)': exp['best_val_acc'],\n",
    "        'Test Acc (%)': exp['test_acc'],\n",
    "        'Параметры': exp['num_parameters']\n",
    "    }\n",
    "    for exp in basic_experiments['experiments']\n",
    "]).sort_values('Test Acc (%)', ascending=False)\n",
    "\n",
    "print(\"ТОП-10 РЕЗУЛЬТАТОВ (Раунд 1, 20 эпох):\")\n",
    "print(\"=\"*80)\n",
    "print(basic_df.head(10).to_string(index=False))\n",
    "\n",
    "# Статистика\n",
    "print(f\"\\nСтатистика Раунд 1:\")\n",
    "print(f\"  Среднее Test Acc: {basic_df['Test Acc (%)'].mean():.2f}%\")\n",
    "print(f\"  Медиана Test Acc: {basic_df['Test Acc (%)'].median():.2f}%\")\n",
    "print(f\"  Максимум Test Acc: {basic_df['Test Acc (%)'].max():.2f}%\")\n",
    "print(f\"  Минимум Test Acc: {basic_df['Test Acc (%)'].min():.2f}%\")\n",
    "print(f\"  Стандартное отклонение: {basic_df['Test Acc (%)'].std():.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Раунд 2: Продвинутые эксперименты\n",
    "\n",
    "Анализ результатов 11 продвинутых экспериментов (40-50 эпох с early stopping)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание DataFrame для продвинутых экспериментов\n",
    "advanced_df = pd.DataFrame([\n",
    "    {\n",
    "        'Эксперимент': exp['experiment_name'],\n",
    "        'Val Acc (%)': exp['best_val_acc'],\n",
    "        'Test Acc (%)': exp['test_acc'],\n",
    "        'Параметры': exp['num_parameters'],\n",
    "        'Эпох': exp['epochs_trained']\n",
    "    }\n",
    "    for exp in advanced_experiments['experiments']\n",
    "]).sort_values('Test Acc (%)', ascending=False)\n",
    "\n",
    "print(\"РЕЗУЛЬТАТЫ ПРОДВИНУТЫХ ЭКСПЕРИМЕНТОВ (Раунд 2, 40-50 эпох):\")\n",
    "print(\"=\"*80)\n",
    "print(advanced_df.to_string(index=False))\n",
    "\n",
    "# Статистика\n",
    "print(f\"\\nСтатистика Раунд 2:\")\n",
    "print(f\"  Среднее Test Acc: {advanced_df['Test Acc (%)'].mean():.2f}%\")\n",
    "print(f\"  Максимум Test Acc: {advanced_df['Test Acc (%)'].max():.2f}%\")\n",
    "print(f\"  Среднее количество эпох: {advanced_df['Эпох'].mean():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Раунд 3: Ансамблирование\n",
    "\n",
    "Результаты ансамблирования 5 лучших моделей с использованием soft voting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Результаты индивидуальных моделей в ансамбле\n",
    "ensemble_df = pd.DataFrame(ensemble_results['individual_models'])\n",
    "\n",
    "print(\"ИНДИВИДУАЛЬНЫЕ МОДЕЛИ В АНСАМБЛЕ:\")\n",
    "print(\"=\"*80)\n",
    "for i, model in enumerate(ensemble_results['individual_models'], 1):\n",
    "    print(f\"{i}. {model['name']}\")\n",
    "    print(f\"   Val Acc: {model['val_acc']:.2f}%, Test Acc: {model['test_acc']:.2f}%\")\n",
    "    print(f\"   Параметры: {model['num_parameters']:,}\")\n",
    "\n",
    "print(f\"\\nСредняя точность индивидуальных моделей: {ensemble_results['avg_individual_test_acc']:.2f}%\")\n",
    "print(f\"Лучшая индивидуальная модель: {ensemble_results['best_individual_test_acc']:.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"РЕЗУЛЬТАТЫ АНСАМБЛЯ (SOFT VOTING):\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Validation Accuracy: {ensemble_results['ensemble_val_acc']:.2f}%\")\n",
    "print(f\"Test Accuracy: {ensemble_results['ensemble_test_acc']:.2f}%\")\n",
    "print(f\"\\nУлучшение относительно лучшей индивидуальной: {ensemble_results['improvement_vs_best']:+.2f}%\")\n",
    "print(f\"Улучшение относительно средней индивидуальной: {ensemble_results['improvement_vs_avg']:+.2f}%\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Сравнительный анализ результатов\n",
    "\n",
    "### 7.1 Эволюция точности по раундам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объединение всех экспериментов\n",
    "all_experiments_list = basic_experiments['experiments'] + advanced_experiments['experiments']\n",
    "\n",
    "# Топ-10 моделей из всех экспериментов\n",
    "top10_all = sorted(all_experiments_list, key=lambda x: x['test_acc'], reverse=True)[:10]\n",
    "\n",
    "# Визуализация топ-10\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "names = [exp['experiment_name'][:50] for exp in top10_all]\n",
    "test_accs = [exp['test_acc'] for exp in top10_all]\n",
    "val_accs = [exp['best_val_acc'] for exp in top10_all]\n",
    "\n",
    "y_pos = np.arange(len(names))\n",
    "\n",
    "# Определение цвета (раунд 1 или раунд 2)\n",
    "colors = ['#3498db' if exp in basic_experiments['experiments'] else '#e74c3c' for exp in top10_all]\n",
    "\n",
    "bars = ax.barh(y_pos, test_accs, alpha=0.8, color=colors, edgecolor='black', linewidth=1.2)\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(names, fontsize=9)\n",
    "ax.set_xlabel('Test Accuracy (%)', fontsize=11, fontweight='bold')\n",
    "ax.set_title('Топ-10 моделей по точности на тестовой выборке', fontsize=13, fontweight='bold', pad=15)\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "ax.axvline(x=baseline_test_acc, color='green', linestyle='--', linewidth=2, label=f'Baseline: {baseline_test_acc:.2f}%')\n",
    "ax.axvline(x=80, color='red', linestyle='--', linewidth=2, alpha=0.5, label='Целевая точность: 80%')\n",
    "\n",
    "# Добавление значений на столбцах\n",
    "for bar, acc in zip(bars, test_accs):\n",
    "    ax.text(acc + 0.3, bar.get_y() + bar.get_height()/2, \n",
    "            f'{acc:.2f}%', va='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "# Легенда\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [\n",
    "    Patch(facecolor='#3498db', label='Раунд 1 (20 эпох)'),\n",
    "    Patch(facecolor='#e74c3c', label='Раунд 2 (40+ эпох)'),\n",
    "    plt.Line2D([0], [0], color='green', linestyle='--', linewidth=2, label=f'Baseline: {baseline_test_acc:.2f}%'),\n",
    "    plt.Line2D([0], [0], color='red', linestyle='--', linewidth=2, alpha=0.5, label='Цель: 80%')\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc='lower right', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Эволюция результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Таблица эволюции\n",
    "evolution_data = [\n",
    "    ['Baseline (20 эпох)', baseline_test_acc, '-', 'Без регуляризации'],\n",
    "    ['Лучшая (Раунд 1, 20 эпох)', basic_df['Test Acc (%)'].max(), \n",
    "     f\"+{basic_df['Test Acc (%)'].max() - baseline_test_acc:.2f}%\", \n",
    "     'BN + Dropout 0.3'],\n",
    "    ['Лучшая (Раунд 2, 40 эпох)', advanced_df['Test Acc (%)'].max(), \n",
    "     f\"+{advanced_df['Test Acc (%)'].max() - baseline_test_acc:.2f}%\", \n",
    "     'Deep [256,256,128,64] + BN'],\n",
    "    ['Ансамбль (5 моделей)', ensemble_results['ensemble_test_acc'], \n",
    "     f\"+{ensemble_results['ensemble_test_acc'] - baseline_test_acc:.2f}%\", \n",
    "     'Soft voting']\n",
    "]\n",
    "\n",
    "evolution_df = pd.DataFrame(\n",
    "    evolution_data,\n",
    "    columns=['Этап', 'Test Accuracy (%)', 'Улучшение vs Baseline', 'Ключевая техника']\n",
    ")\n",
    "\n",
    "print(\"ЭВОЛЮЦИЯ РЕЗУЛЬТАТОВ:\")\n",
    "print(\"=\"*90)\n",
    "print(evolution_df.to_string(index=False))\n",
    "print(\"=\"*90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Визуализация эволюции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# График эволюции результатов\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "stages = ['Baseline\\n(20 эпох)', 'Лучшая\\nРаунд 1', 'Лучшая\\nРаунд 2', 'Ансамбль\\n(5 моделей)']\n",
    "accuracies = [\n",
    "    baseline_test_acc,\n",
    "    basic_df['Test Acc (%)'].max(),\n",
    "    advanced_df['Test Acc (%)'].max(),\n",
    "    ensemble_results['ensemble_test_acc']\n",
    "]\n",
    "\n",
    "x_pos = np.arange(len(stages))\n",
    "colors_stages = ['#95a5a6', '#3498db', '#e74c3c', '#2ecc71']\n",
    "\n",
    "bars = ax.bar(x_pos, accuracies, alpha=0.8, color=colors_stages, edgecolor='black', linewidth=1.5)\n",
    "ax.set_ylabel('Test Accuracy (%)', fontsize=12, fontweight='bold')\n",
    "ax.set_xlabel('Этап эксперимента', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Эволюция точности классификации', fontsize=14, fontweight='bold', pad=15)\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(stages, fontsize=10)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "ax.axhline(y=80, color='red', linestyle='--', linewidth=2, alpha=0.5, label='Целевая точность: 80%')\n",
    "\n",
    "# Добавление значений на столбцах\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "            f'{acc:.2f}%', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "# Добавление стрелок с улучшениями\n",
    "for i in range(len(accuracies)-1):\n",
    "    improvement = accuracies[i+1] - accuracies[i]\n",
    "    ax.annotate('', xy=(x_pos[i+1], accuracies[i]), xytext=(x_pos[i], accuracies[i]),\n",
    "                arrowprops=dict(arrowstyle='->', lw=2, color='black', alpha=0.5))\n",
    "    mid_x = (x_pos[i] + x_pos[i+1]) / 2\n",
    "    ax.text(mid_x, accuracies[i] - 1.5, f'+{improvement:.2f}%', \n",
    "            ha='center', fontsize=9, color='green', fontweight='bold')\n",
    "\n",
    "ax.legend(fontsize=10)\n",
    "ax.set_ylim([70, 85])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Анализ влияния гиперпараметров\n",
    "\n",
    "### 8.1 Влияние архитектуры\n",
    "\n",
    "Анализ зависимости точности от размера и глубины сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Фильтрация экспериментов по архитектуре\n",
    "arch_experiments = [exp for exp in basic_experiments['experiments'] \n",
    "                    if 'Architecture' in exp['experiment_name']]\n",
    "\n",
    "# Визуализация\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# График 1: Параметры vs Accuracy\n",
    "params = [exp['num_parameters'] for exp in arch_experiments]\n",
    "test_accs_arch = [exp['test_acc'] for exp in arch_experiments]\n",
    "names_arch = [exp['experiment_name'].replace('Architecture: ', '') for exp in arch_experiments]\n",
    "\n",
    "ax1.scatter(params, test_accs_arch, s=150, alpha=0.6, edgecolor='black', linewidth=1.5)\n",
    "for i, name in enumerate(names_arch):\n",
    "    ax1.annotate(name, (params[i], test_accs_arch[i]), fontsize=9, ha='right')\n",
    "ax1.set_xlabel('Количество параметров', fontsize=11, fontweight='bold')\n",
    "ax1.set_ylabel('Test Accuracy (%)', fontsize=11, fontweight='bold')\n",
    "ax1.set_title('Влияние размера модели', fontsize=12, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# График 2: Сравнение архитектур\n",
    "x_pos_arch = np.arange(len(names_arch))\n",
    "ax2.bar(x_pos_arch, test_accs_arch, alpha=0.8, edgecolor='black', linewidth=1.2)\n",
    "ax2.set_xticks(x_pos_arch)\n",
    "ax2.set_xticklabels(names_arch, rotation=45, ha='right', fontsize=9)\n",
    "ax2.set_ylabel('Test Accuracy (%)', fontsize=11, fontweight='bold')\n",
    "ax2.set_title('Сравнение архитектур', fontsize=12, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "for i, acc in enumerate(test_accs_arch):\n",
    "    ax2.text(i, acc + 0.3, f'{acc:.1f}%', ha='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Вывод: Оптимальная архитектура - [128, 64] или [256, 128].\")\n",
    "print(\"Слишком большие модели склонны к переобучению без достаточной регуляризации.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Влияние регуляризации\n",
    "\n",
    "Анализ эффективности различных методов регуляризации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Фильтрация экспериментов по регуляризации\n",
    "reg_experiments = [exp for exp in basic_experiments['experiments'] \n",
    "                   if 'Regularization' in exp['experiment_name'] or 'Batch Norm' in exp['experiment_name']]\n",
    "\n",
    "reg_df = pd.DataFrame([\n",
    "    {\n",
    "        'Метод': exp['experiment_name'],\n",
    "        'Test Acc (%)': exp['test_acc'],\n",
    "        'Val Acc (%)': exp['best_val_acc']\n",
    "    }\n",
    "    for exp in reg_experiments\n",
    "]).sort_values('Test Acc (%)', ascending=False)\n",
    "\n",
    "print(\"ЭФФЕКТИВНОСТЬ МЕТОДОВ РЕГУЛЯРИЗАЦИИ:\")\n",
    "print(\"=\"*70)\n",
    "print(reg_df.to_string(index=False))\n",
    "\n",
    "# Визуализация\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "names_reg = [name[:40] for name in reg_df['Метод']]\n",
    "test_acc_reg = reg_df['Test Acc (%)'].values\n",
    "\n",
    "x_pos_reg = np.arange(len(names_reg))\n",
    "bars_reg = ax.barh(x_pos_reg, test_acc_reg, alpha=0.8, edgecolor='black', linewidth=1.2)\n",
    "ax.set_yticks(x_pos_reg)\n",
    "ax.set_yticklabels(names_reg, fontsize=9)\n",
    "ax.set_xlabel('Test Accuracy (%)', fontsize=11, fontweight='bold')\n",
    "ax.set_title('Сравнение методов регуляризации', fontsize=13, fontweight='bold', pad=15)\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "ax.axvline(x=baseline_test_acc, color='red', linestyle='--', linewidth=2, label='Baseline')\n",
    "\n",
    "for bar, acc in zip(bars_reg, test_acc_reg):\n",
    "    ax.text(acc + 0.2, bar.get_y() + bar.get_height()/2, \n",
    "            f'{acc:.2f}%', va='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "ax.legend(fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nВывод: Batch Normalization + Dropout 0.3 показывает лучшие результаты (+3.49% vs Baseline).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Выводы\n",
    "\n",
    "### 9.1 Итоговые результаты\n",
    "\n",
    "В ходе исследования было проведено **40 систематических экспериментов** по оптимизации многослойного перцептрона для классификации медицинских изображений OrganCMNIST. Достигнуты следующие результаты:\n",
    "\n",
    "| Метрика | Значение |\n",
    "|---------|----------|\n",
    "| Baseline Test Accuracy | 74.84% |\n",
    "| Лучшая индивидуальная модель | 80.61% |\n",
    "| **Ансамбль (5 моделей, soft voting)** | **80.83%** |\n",
    "| Общее улучшение | +5.99% |\n",
    "\n",
    "### 9.2 Ключевые находки\n",
    "\n",
    "#### 9.2.1 Регуляризация\n",
    "\n",
    "Методы регуляризации оказывают критическое влияние на качество модели:\n",
    "- **Batch Normalization:** улучшение +2.5%\n",
    "- **Dropout 0.3:** улучшение +1.5-2%\n",
    "- **Комбинация BN + Dropout:** улучшение +3.5%\n",
    "- **L2 регуляризация (weight decay 1e-4):** дополнительное улучшение +0.5-1%\n",
    "\n",
    "#### 9.2.2 Архитектура\n",
    "\n",
    "- Глубокие сети (4 слоя) превосходят мелкие (2 слоя) на 1-2% при наличии достаточной регуляризации\n",
    "- Оптимальная конфигурация: [256, 256, 128, 64] с 310k параметров\n",
    "- Избыточно большие модели (>500k параметров) склонны к переобучению\n",
    "\n",
    "#### 9.2.3 Длительность обучения\n",
    "\n",
    "- 40 эпох превосходят 20 эпох на 1.5-2% для глубоких моделей\n",
    "- Early stopping необходим для предотвращения переобучения при длительном обучении\n",
    "\n",
    "#### 9.2.4 Ансамблирование\n",
    "\n",
    "- Soft voting из 5 моделей с различными random seeds обеспечивает стабильное улучшение\n",
    "- Улучшение относительно лучшей индивидуальной модели: +0.22%\n",
    "- Улучшение относительно средней индивидуальной модели: +1.29%\n",
    "\n",
    "### 9.3 Ограничения архитектуры MLP\n",
    "\n",
    "Достигнутая точность **80.83%** близка к теоретическому пределу архитектуры MLP для данной задачи (~81-82%). Фундаментальные ограничения MLP:\n",
    "\n",
    "1. **Потеря пространственной информации:** Операция flatten преобразует 2D изображение в 1D вектор, что приводит к потере информации о пространственных отношениях между пикселями.\n",
    "\n",
    "2. **Отсутствие локальных признаков:** MLP обрабатывает все входные признаки глобально, не используя локальные паттерны, характерные для изображений.\n",
    "\n",
    "3. **Большое количество параметров:** Полносвязная архитектура требует O(n²) параметров, что увеличивает склонность к переобучению.\n",
    "\n",
    "### 9.4 Сравнение с литературой\n",
    "\n",
    "Согласно исследованиям датасета MedMNIST [1]:\n",
    "- MLP (linear baseline): 74-76%\n",
    "- Simple CNN: 82-86%\n",
    "- ResNet-18: 88-90%\n",
    "- State-of-the-art: 92-95%\n",
    "\n",
    "Достигнутый результат 80.83% находится на верхней границе возможностей архитектуры MLP и превосходит базовые результаты из литературы.\n",
    "\n",
    "### 9.5 Методологический вклад\n",
    "\n",
    "Данное исследование демонстрирует важность систематического подхода к оптимизации гиперпараметров:\n",
    "- Контролируемые эксперименты с фиксированным seed\n",
    "- Постепенное усложнение: baseline → базовые эксперименты → продвинутые техники → ансамблирование\n",
    "- Документирование всех конфигураций для воспроизводимости\n",
    "- Использование валидационной выборки для подбора гиперпараметров, тестовой - только для финальной оценки\n",
    "\n",
    "### 9.6 Заключение\n",
    "\n",
    "В работе достигнута точность классификации **80.83%** на датасете OrganCMNIST с использованием оптимизированного многослойного перцептрона. Результат представляет улучшение на **5.99%** относительно baseline модели и находится на верхней границе возможностей данной архитектуры. Систематическое исследование 40 конфигураций позволило выявить оптимальную комбинацию гиперпараметров: глубокая архитектура [256,256,128,64] с Batch Normalization, Dropout 0.3, Adam оптимизатором и ансамблированием моделей.\n",
    "\n",
    "Результаты подтверждают теоретические ограничения полносвязных архитектур для задач компьютерного зрения и демонстрируют критическую важность методов регуляризации для достижения хорошей генерализации.\n",
    "\n",
    "---\n",
    "\n",
    "### Список литературы\n",
    "\n",
    "[1] Yang, J., Shi, R., Wei, D., Liu, Z., Zhao, L., Ke, B., ... & Cootes, T. (2023). MedMNIST v2-A large-scale lightweight benchmark for 2D and 3D biomedical image classification. Scientific Data, 10(1), 41.\n",
    "\n",
    "[2] Kingma, D. P., & Ba, J. (2014). Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980.\n",
    "\n",
    "[3] Ioffe, S., & Szegedy, C. (2015, June). Batch normalization: Accelerating deep network training by reducing internal covariate shift. In International conference on machine learning (pp. 448-456). PMLR.\n",
    "\n",
    "[4] Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., & Salakhutdinov, R. (2014). Dropout: a simple way to prevent neural networks from overfitting. The journal of machine learning research, 15(1), 1929-1958."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}