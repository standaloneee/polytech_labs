
================================================================================
ИТОГОВЫЙ ОТЧЕТ ПО ЭКСПЕРИМЕНТАМ
================================================================================

Дата создания: 2026-01-30 18:32:18
Дата экспериментов: 2026-01-30 18:29:55
Всего экспериментов: 24

================================================================================
1. BASELINE МОДЕЛЬ
================================================================================

Архитектура: [128, 64]
Количество параметров: 109,451
Функция активации: RELU
Dropout: 0.0
Batch Normalization: Нет

Результаты:
  - Training Epochs: 20
  - Learning Rate: 0.001
  - Best Validation Accuracy: 89.55%
  - Test Loss: 1.4310
  - **Test Accuracy: 74.84%**

Проблемы:
  - Наблюдается переобучение (высокая точность на обучающей выборке)
  - Необходима регуляризация

================================================================================
2. ЛУЧШАЯ МОДЕЛЬ
================================================================================

Эксперимент: Batch Norm: BN + Dropout 0.3
Архитектура: [128, 64]
Количество параметров: 109,835

Конфигурация:
  - use_batch_norm: True
  - dropout: 0.3
  - lr: 0.001

Результаты:
  - Best Validation Accuracy: 91.22%
  - Test Loss: 0.7473
  - **Test Accuracy: 78.33%**

Улучшение относительно baseline: +3.49%

================================================================================
3. РЕЗУЛЬТАТЫ ПО КАТЕГОРИЯМ ЭКСПЕРИМЕНТОВ
================================================================================

Architecture:
  Количество экспериментов: 5
  Средняя Test Accuracy: 74.96%

  Лучший результат:
    - Architecture: Large
    - Test Acc: 76.92%

  Худший результат:
    - Architecture: Small
    - Test Acc: 72.87%

  Разброс: 4.05%

Regularization:
  Количество экспериментов: 7
  Средняя Test Accuracy: 75.92%

  Лучший результат:
    - Regularization: Dropout 0.3
    - Test Acc: 76.62%

  Худший результат:
    - Regularization: No Reg
    - Test Acc: 74.84%

  Разброс: 1.78%

Batch Norm:
  Количество экспериментов: 3
  Средняя Test Accuracy: 76.82%

  Лучший результат:
    - Batch Norm: BN + Dropout 0.3
    - Test Acc: 78.33%

  Худший результат:
    - Batch Norm: Without BN
    - Test Acc: 74.84%

  Разброс: 3.49%

Activation:
  Количество экспериментов: 4
  Средняя Test Accuracy: 74.48%

  Лучший результат:
    - Activation: elu
    - Test Acc: 76.40%

  Худший результат:
    - Activation: tanh
    - Test Acc: 71.93%

  Разброс: 4.47%

LR:
  Количество экспериментов: 5
  Средняя Test Accuracy: 74.78%

  Лучший результат:
    - LR: LR 0.001 + StepLR
    - Test Acc: 75.33%

  Худший результат:
    - LR: LR 0.0001
    - Test Acc: 73.77%

  Разброс: 1.56%

================================================================================
4. ТОП-5 МОДЕЛЕЙ
================================================================================

1. Batch Norm: BN + Dropout 0.3
   Test Accuracy: 78.33%
   Val Accuracy: 91.22%
   Параметры: 109,835
   Конфигурация: {'hidden_sizes': [128, 64], 'use_batch_norm': True, 'dropout': 0.3, 'num_epochs': 20, 'lr': 0.001}

2. Batch Norm: With BN
   Test Accuracy: 77.29%
   Val Accuracy: 89.84%
   Параметры: 109,835
   Конфигурация: {'hidden_sizes': [128, 64], 'use_batch_norm': True, 'dropout': 0.0, 'num_epochs': 20, 'lr': 0.001}

3. Architecture: Large
   Test Accuracy: 76.92%
   Val Accuracy: 89.05%
   Параметры: 235,275
   Конфигурация: {'hidden_sizes': [256, 128], 'num_epochs': 20, 'lr': 0.001}

4. Regularization: Dropout 0.3
   Test Accuracy: 76.62%
   Val Accuracy: 90.13%
   Параметры: 109,451
   Конфигурация: {'hidden_sizes': [128, 64], 'dropout': 0.3, 'weight_decay': 0.0, 'num_epochs': 20, 'lr': 0.001}

5. Regularization: Dropout 0.3 + L2 1e-4
   Test Accuracy: 76.48%
   Val Accuracy: 90.26%
   Параметры: 109,451
   Конфигурация: {'hidden_sizes': [128, 64], 'dropout': 0.3, 'weight_decay': 0.0001, 'num_epochs': 20, 'lr': 0.001}

================================================================================
5. ОБЩАЯ СТАТИСТИКА
================================================================================

Test Accuracy:
  - Минимум: 71.93%
  - Максимум: 78.33%
  - Среднее: 75.35%
  - Медиана: 75.18%
  - Стандартное отклонение: 1.35%

Validation Accuracy:
  - Минимум: 88.21%
  - Максимум: 91.22%
  - Среднее: 89.44%
  - Медиана: 89.38%

Val-Test Gap (среднее): 14.08%

================================================================================
6. КЛЮЧЕВЫЕ ВЫВОДЫ
================================================================================

1. РЕГУЛЯРИЗАЦИЯ КРИТИЧЕСКИ ВАЖНА
   Модели с Dropout и/или Weight Decay показывают значительно лучшие результаты
   на тестовой выборке, что указывает на меньшее переобучение.

2. BATCH NORMALIZATION ЭФФЕКТИВНА
   Использование Batch Normalization ускоряет обучение и часто приводит к
   улучшению обобщающей способности модели.

3. БАЛАНС СЛОЖНОСТИ И ОБОБЩЕНИЯ
   Увеличение количества параметров не всегда приводит к улучшению результатов.
   Важен баланс между выразительностью модели и склонностью к переобучению.

4. LEARNING RATE И SCHEDULERS
   Правильный выбор скорости обучения критичен. Schedulers помогают адаптивно
   изменять LR в процессе обучения и могут улучшить результаты.

5. ФУНКЦИИ АКТИВАЦИИ
   ReLU остается надежным выбором. Альтернативы (LeakyReLU, ELU) дают
   небольшое улучшение в некоторых случаях.

================================================================================
7. ПРОБЛЕМЫ И НАБЛЮДЕНИЯ
================================================================================

1. ПЕРЕОБУЧЕНИЕ
   Основная проблема - модели показывают высокую точность на обучающей выборке
   (>95%), но значительно хуже на тестовой (~75%). Это указывает на необходимость
   более агрессивной регуляризации.

2. VAL-TEST GAP
   Наблюдается разрыв между точностью на валидационной и тестовой выборках.
   Это может указывать на различия в распределении данных или на переобучение
   под валидационную выборку при подборе гиперпараметров.

3. ОГРАНИЧЕНИЯ MLP
   Многослойный перцептрон не учитывает пространственную структуру изображений,
   что ограничивает его способность к извлечению признаков.

================================================================================
8. РЕКОМЕНДАЦИИ ДЛЯ ДАЛЬНЕЙШЕГО УЛУЧШЕНИЯ
================================================================================

1. Использовать сверточные нейронные сети (CNN) для лучшего извлечения
   признаков из изображений

2. Применить аугментацию данных (повороты, смещения, зеркальные отражения)
   для увеличения разнообразия обучающей выборки

3. Исследовать ансамблирование моделей (voting, stacking)

4. Попробовать другие оптимизаторы (SGD with momentum, AdamW)

5. Использовать раннюю остановку (early stopping) для предотвращения
   переобучения

6. Применить cross-validation для более надежной оценки качества

7. Исследовать transfer learning с предобученными моделями

================================================================================
9. ЗАКЛЮЧЕНИЕ
================================================================================

В ходе работы была проведена систематическая оптимизация гиперпараметров
многослойного перцептрона для классификации медицинских изображений из
датасета OrganCMNIST.

Было протестировано 24 различных конфигураций модели, что позволило
достичь точности 78.33% на тестовой выборке - улучшение на
3.49% по сравнению с baseline моделью.

Ключевым фактором успеха стало использование регуляризации (Dropout и/или
Weight Decay) в сочетании с Batch Normalization. Эта комбинация позволила
значительно снизить переобучение и улучшить обобщающую способность модели.

Систематический подход к экспериментам позволил получить ценные инсайты о
влиянии различных компонентов архитектуры на итоговый результат, что будет
полезно для дальнейших исследований.

================================================================================
КОНЕЦ ОТЧЕТА
================================================================================
